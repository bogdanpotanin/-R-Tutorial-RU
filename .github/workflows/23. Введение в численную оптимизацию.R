# --------
# Потанин Богдан Станиславович
# Введение в R
# Урок 23. Введение в численную оптимизацию
# --------

# Численные методы оптимизации позволяют приближенно
# находить максимум и минимум функции

# Для ознакомления с численными методами оптимизации рекомендуется прочесть
# https://www.researchgate.net/publication/313867455_Numerical_Optimization_Methods_in_Economics

# Методы численной оптимизации имеют множество
# классификаций, включая следующие:
# Классификация 1:
# 1. Локальные - находят локальный максимум или минимум (BFGS, BHHH, gradient descent)
# 2. Глобальные - пытаются найти глобальный максимум или минимум (genetic algorithm, SANN)
# Классификация 2:
# 1. Используют информацию о значениях функции (Nelder-Mead)
# 2. Используют информацию о градиенте функции (gradient descent, conjugate gradient)
# 3. Используют информацию о Гессиане функции (Newton, BFGS, BHHH)

# В качестве примера рассмотрим метод численной оптимизации, именуемый
# градиентным спуском (gradient descent). Запрограммируем классический 
# вариант градиентного спуска с фиксированной скоростью шага (learning rate) 
# и условием остановки (termination condition), определяемым числом итераций,
# а также относительной погрешностью

# Краткое описание алгоритма поиска локального
# минимума функции при помощи градиентного спуска:
# 1. Устанавливаете критерий остановки алгоритма, например,
#    по истечению такого-то числа итераций (шагов) или, если
#    относительная погрешность новой точки x_new по отношению
#    к предыдущей точке x_old меньше, чем относительная 
#    погрешность решения reltol:
#    |(x_new - x_old) / x_old| < reltol
#    Если функция оптимизируется по нескольким аргументам, то
#    точки будут векторами и неравенство, написанное выше, должно
#    соблюдаться для всех соответствующих элементов x_new и x_old
#    Если истинная точка максимума x* близка к 0, то способ, описанный
#    выше, по очевидным причинам не срабатывает, что требует использование
#    абослютной погрешности abstol, задающей следующий критерий остановки:
#    |x_new - x_old| < abstol
# 2. Берете начальную точку x0
# 3. Рассчитываете градиент df функции f в начальной точке df(x0)
# 4. Устанавливаете новую точку вместо начальной x1 = x0 - a * df(x0),
#    где a > 0 определяет скорость алгоритма.
# 5. Повторяете шаги 3 и 4 до тех пор, пока не будет 
#    соблюден критерий остановки алгоритма из шага 1

library("numDeriv")

gd <- function(fn,                                 # оптимизируемая функция
               x0,                                 # вектор начальных значений
               iter = 1000,                        # число итераций
               reltol = sqrt(.Machine$double.eps), # относительная погрешность решения
               learning_rate = 0.01,               # скорость шага
               is_max = FALSE,                     # если TRUE, то функция максимизируется, 
                                                   # а если FALSE - минимизируется
               ...)                                # дополнительные аргументы, учитываемые fn                              
                                                   
{
  
  if (is_max)                                      # по умолчанию метод градиентного спуска 
  {                                                # предназначен для поиска локального минимума, 
    learning_rate <- -learning_rate                # поэтому, для поиска максимума необходимо изменить 
                                                   # знак learning rate на противоположный
  }
  
  x <- matrix(NA,                                  # матрица, в котрой мы будем 
              nrow = iter,                         # сохранять точки, по которым
              ncol = length(x0))                   # проходится алгоритм в поисках
                                                   # минимума (максимума)
  x[1, ] <- x0                                     # присваиваем первой из точек
                                                   # начальное значение

  for (i in 2:iter)                                # каждую итерацию алгоритма
  {
    x[i, ] <- x[i - 1, ] -                         # рассчитываем новую точку,
              learning_rate * grad(fn, x[i - 1, ], # используя предыдущую
                                   ... = ...)      # и учитывая дополнительные
                                                   # аргументы fn через ...
    if (all(abs((x[i - 1, ] - x[i, ]) /            # проверяем соблюдение условия
        x[i - 1, ]) < reltol))                     # остановки алгоритма
    {                                              # если оно соблюдено, то
      x <- x[1:i, ]                                # убираем из матрицы точек
      break                                        # пропуски и прекращаем итерации
    }
  }

  solution <- tail(x, 1)                           # точка локального максимума, посчитанная
                                                   # с некоторой погрешностью
  
  return_list <- list("points" = x,                # возвращаем все точки по которым 
                      "solution" = solution,       # прошелся алгоритм и решение как
                                                   # последнюю из этих точек
                      "fn_value" = fn(solution,    # значение функции в        
                                      ... = ...),  # точке максимума
                      "fn_grad" = grad(fn,         # градиент функции
                                       solution,   # в точке максимума
                                       ... = ...))  
                                                   
  
  return(return_list)
}

# Примеры применения численных методов оптимизации
# для поиска максимумов функции

# Пример №1 
# Функция: 2 * ln(x) + 3 * ln(5 - x)
# Максимум в точке: x* = 2
# Запрограммируем функцию
f1 <- function(x)
{
  value <- 2 * log(x) + 3 * log(5 - x) # считаем значение функции
  
  return(value)                        # возвращаем значение, 
                                       # посчитанное в функции                   
}

# Посмотрим на нашу функцию
points <- seq(from = 0.001,  # создаем вектор из последовательности
              to = 4.999,    # значений от from до to с шагом by
              by = 0.001)
plot(points, f1(points),
     xlab = "x", ylab = "f1")

# Для начала воспользуемся собственным оптимизатором
gd_result <- gd(fn = f1, x0 = 0.5, iter = 10000, 
                learning_rate = 0.01, is_max = TRUE,
                reltol = 0.000001)
gd_result$solution                                          # точка максимума
gd_result$points                                            # все точки, по которым прошел алгоритм
plot(gd_result$points, xlab = "iteration", ylab = "point")  # графическая визуализация точек
# Теперь применим встроенный оптимизатор
x0 <- 0.5                                                    # задаем любую начальную точку, 
                                                             # в которой наша функция определена
opt_result <- optim(par = x0,                                # начальная точка
                    fn = f1,                                 # минимизируемая функция
                    method = "BFGS",                         # метод численной оптимизации
                    control = list("maxit" = 100000,         # максимальное количество итераций
                                   "fnscale" = -1,           # ставим -1, чтобы сделать 
                                                             # задачу максимизационной.
              "reltol" = sqrt(.Machine$double.eps) * 0.01))  # увеличиваем требуемую 
                                                             # точность решения
                                                             
# Рассмотрим полученные по результатам 
# решения максимизационной задачи значения
opt_result$par         # точка максимума
opt_result$value       # значение функции в точке максимума
opt_result$convergence # если равно 0, то численная оптимизация прошла успешно

# Пример 2
# Функция: (x1+x2+1)^2-5x1^2-10x2^2
# Максимум в точке: x* = (2 / 7, 1 / 7) ~= (0.2857143, 0.1428571)
# Запрограммируем функцию
f2 <- function (x)
{
  value <- (x[1] + x[2] + 1) ^ 2 - 
           5 * x[1] ^ 2 - 
           10 * x[2] ^ 2
  
  return(value)                       
}      
# Для начала воспользуемся собственным оптимизатором
gd(fn = f2, x0 = c(1, 2), iter = 1000, 
   learning_rate = 0.01, is_max = TRUE)
# Применим оптимизатор
x0 <- c(1, 2)
opt_result <- optim(par =  x0,    
                    fn = f2,
                    method = "BFGS",
                    control = list("maxit" = 1000,
                                   "fnscale" = -1,
                                   "reltol" = sqrt(.Machine$double.eps) * 0.01))

# Рассмотрим полученные по результатам 
# решения максимизационной задачи значения
opt_result$par         # точка максимума
opt_result$value       # значение функции в точке максимума
opt_result$convergence # если равно 0, то численная оптимизация прошла успешно

# Также, получить результат быстрей и точней можно 
# за счет предоставления аналитического градиента
f2_grad <- function(x)
{
  d_x1 <- 2 * (x[1] + x[2] + 1) - 10 * x[1]
  d_x2 <- 2 * (x[1] + x[2] + 1) - 20 * x[2]
  gr <- c(d_x1, d_x2)
  
  return(gr)                       
}      

# Считаем с учетом градиента, добавляя
# его через аргумент gr
opt_result_gr <- optim(par =  x0,    
                       fn = f2,
                       gr = f2_grad,                    # функция для расчета градиента
                       method = "BFGS",
                       control = list("maxit" = 1000,
                                      "fnscale" = -1,
                                      "reltol" = sqrt(.Machine$double.eps) * 0.01))
opt_result_gr$par
opt_result_gr$value

# Если функция имеет дополнительные аргументы, по которым
# не нужно оптимизировать функцию, то их можно подать
# по аналогии с тем, как они подавались в функцию grad()
f3 <- function(x, a, b)
{
  value <- a * (x[1] + x[2] + 1) ^ 2 - 
    b[1] * x[1] ^ 2 - 
    b[2] * x[2] ^ 2
  
  return(value)                       
}  
# Используем встроенную функцию
x0 <- c(1, 2)
opt_result_gr <- optim(par =  x0,    
                       fn = f3,
                       method = "BFGS",
                       control = list("maxit" = 1000,
                                      "fnscale" = -1,
                                      "reltol" = sqrt(.Machine$double.eps) * 0.01),
                       a = 1, b = c(5, 10)) # дополнительные аргументы для f3, 
                                            # могут быть любыми, включая лист
opt_result_gr$par
# Используем нашу функцию
gd(fn = f3, x0 = c(1, 2), iter = 1000, 
   learning_rate = 0.01, is_max = TRUE,
   a = 1, b = c(5, 10))

# Недостатком локальных оптимизаторов является то, что они
# находят лишь локальный, но не глобальный максимум
# Следующая функция имеет два локальных максимума
f4 <- function(x)
{
  value <- 3 * x ^ 2 -                 # считаем значение функции
           x ^ 4 + 0.5 * x 
  
  return(value)                        # возвращаем значение, 
                                       # посчитанное в функции  
}

# Посмотрим на нашу функцию и
# обнаружим, что у нее имеются
# два локальных максимума
points <- seq(from = -2,     # создаем вектор из последовательности
              to = 2,        # значений от from до to с шагом by
              by = 0.001)
plot(points, f4(points),
     xlab = "x", ylab = "f4")

# Воспользуемся градиентным спуском 
# для поиска локальных максимумов
m_1 <- gd(f4, -0.5, 1000, is_max = TRUE)$solution  # первый локальный максимум
m_2 <- gd(f4, 0.5, 1000, is_max = TRUE)$solution   # второй локальный (он же глобальный) максимум
c(f4(m_1), f4(m_2))                                # сравним значения функции в этих точках

# Для поиска глобального максимума можно использовать
# глобальные оптимизаторы, например, генетический алгоритм
install.packages("GA")
library("GA")
ga_result <- ga(type = "real-valued",     # воспринимаем оптимизируемые параметры
                                          # как вещественные числа
                fitness = f4,             # максимизируемая функция
                lower = -5,               # векторы верхних и нижних границ,
                upper = 5,                # в которых ищутся оптимальные значения параметров
                seed = "8")               # в целях воспроизводимости
ga_result_summary <- summary(ga_result)
ga_result_summary$solution
# Подробней про генетический алгоритм и его использование в R можно прочитать в:
# https://cran.r-project.org/web/packages/GA/vignettes/GA.html
# https://www.jstatsoft.org/index.php/jss/article/view/v053i04/v53i04.pdf
# https://journal.r-project.org/archive/2017/RJ-2017-008/RJ-2017-008.pdf

# ЗАДАНИЯ
  # 1. Найдите максимум функции ln(x) - exp(x), достигающей
  #    максимума в точке x* = 0.56714
{
  myFunc <- function(x)
  {
    return(log(x) - exp(x))
  }
  opt_result <- optim(par =  2,    
                      fn = myFunc,
                      method = "BFGS",
                      control = list("maxit" = 1000,
                      "fnscale" = -1))
  opt_result$par
}
  # 2. Найдите максимум функции (x-y) ^ (1/2) - x / (y ^ (1/3)), достигающей
  #    максимума в точке x* = (3 / 512, 1 / 512) ~= (0.005859375, 0.001953125)
  #    Чтобы получить достаточно точный результат используйте аналитический градиент.
{
  myFunc <- function(x)
  {
    return((x[1] - x[2]) ^ 0.5 - 
           x[1] / x[2] ^ (1 / 3))
  }
  myFunc_gr <- function(x)
  {
    d_x1 <- 0.5 / sqrt(x[1] - x[2]) - 1 / x[2] ^ (1 / 3)
    d_x2 <- -0.5 / sqrt(x[1] - x[2]) + (1 / 3) * x[1] / x[2] ^ (4 / 3)
    gr <- c(d_x1, d_x2)
    
    return(gr)
  }
  opt_result <- optim(par =  c(0.2, 0.1),    
                      fn = myFunc,
                      gr = myFunc_gr,
                      method = "BFGS",
                      control = list("maxit" = 10000,
                                     "fnscale" = -1,
                                     "reltol" = sqrt(.Machine$double.eps) * 0.01))
  opt_result$par
}
  # 3. Эксперементируя с начальной точкой найдите оба локальных 
  #    максимума (оба же будут глобальными) функции -(x^2-1)^2-(x^2*y-x-1)^2.
  # 4. Напишите собственный оптимизатор на основе градиентного спуска (gradient descent) c
  #    изменяющимся learning rate и грамотно прописанными termination condition.
  #    https://en.wikipedia.org/wiki/Gradient_descent
  #    В качестве входных аргументов оптимизатор должен принимать функцию и вектор начальных точек.
  #    Возвращать оптимизатор должен вектор точек, в которых функция достигает локального максимума.
  # 5. Повторите все задания и примеры с помощью собственного оптимизатора.