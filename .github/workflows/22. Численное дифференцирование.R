# --------
# Потанин Богдан Станиславович
# Введение в R
# Урок 22. Численное дифференцирование
# --------

# Численное дифференцирование позволяет находить
# частные производные функции с небольшой погрешностью.

# Чтобы приблизительно рассчитать производную 
# функции f(x) от x часто используется следующая формула:
# f'(x) ~= (f(x + eps) - f(x)) / eps,
# где в качестве eps берется достаточно малое значение
# и ~= читается как "приблизительно равно".

# Чем меньше eps, тем, обычно, меньше погрешность 
# вычислений. Однако, при использовании слишком малых
# значений eps компьютер может посчитать f(x + eps) с
# погрешностью, которая окажется больше, чем погрешность,
# возникавшая вследствие больших значений eps. Чтобы
# соблюсти баланс между этими погрешностями как правило
# полагают:
# eps = sqrt(mp) * x, 
# где mp это машинный эпсилон (machine precision).

# Попробуем найти производную x^2 в точке 10
# при помощи численного дифференцирования
x <- 10
eps <- sqrt(.Machine$double.eps) * x          # устанавливаем eps по формуле
2 * x                                         # считаем производную аналитически
((x + eps) ^ 2 - x ^ 2) / eps                 # считаем производную численно
                                              # методом forward difference
((x + eps) ^ 2 - (x - eps) ^ 2) / (2 * eps)   # считаем производную численно
                                              # методом central difference,
                                              # обеспечивающим меньшую погрешность
# Существуют и иные методы численного дифференцирования,
# включая метод Ричардсона, найти и программно реализовать
# которые, как правило, довольно просто.

# Запрограммируем следующую функцию:
# f(x1, x2) = (x1 ^ 2) + (x2 ^ 3) - (x1 * x2)
f <- function(x)
{
  return(x[1] ^ 2 + x[2] ^ 3 - x[1] * x[2])
}
# Найдем её частные производные в точке (2, 3) 
# при помощи численного метода дифференцирования
# При этом настоящие значения производных в этой 
# точке равны 1 и 25 соответственно
x <- c(2, 3)
eps <- sqrt(.Machine$double.eps) * x                # выберем маленькое приращение
d_x1 <- (f(c(x[1] + eps[1], x[2])) - f(x)) / eps[1] # частная производная по x1
d_x2 <- (f(c(x[1], x[2] + eps[2])) - f(x)) / eps[2] # частная производная по x2
matrix(c(d_x1, d_x2), ncol = 1)                     # численный градиент

# Теперь повторим это при помощи 
# специальной встроенной функции
install.packages("numDeriv")
library("numDeriv")
grad(func = f,                # определяем функцию, которую будем дифференцировать
     x = x,                   # выбираем точку, в которой будем искать градиент 
     method = "Richardson")   # выбираем метод численного дифференцирования
                              # Метод "Richardson" предполагает достаточно долгие
                              # расчеты, но обеспечивает малую погрешность
                              # Метод "simple" работает быстро, но имеет
                              # погрешность заметно большую, чем метод "Richardson"

# По аналогии нетрудно рассчитать и Гессиан
hessian(func = f, x = x)

# В данных функциях можно учитывать и дополнительные аргументы,
# по которым не будет осуществляться дифференцирование
f2 <- function(x, a = 1, b = 1, c = 1)
{
  return(a * x[1] ^ 2 + b * x[2] ^ 3 - c * x[1] * x[2])
}

grad(func = f2,
     x = x,                     # дифференцирование осуществляются лишь по
                                # вектору аргументов, указанных в x
     method = "Richardson",
     a = 3, b = 2, c = -2)      # указываем дополнительные аргументы функции,
                                # по которым не будет осуществляться дифференцирование


  # ЗАДАНИЯ
    # 1. Найдите градиент и Гессиан функции
    #    f1(x1, x2, x3) = exp(x1 ^ x2 / log(sqrt(x3))) 
    #    в точке (1, 2, 3) численным методом
{
  f1 <- function(x)
  {
    return(exp(x[1] ^ x[2] / log(sqrt(x[3]))))
  }
  x <- c(1, 2, 3)
  grad(f1, x)
  hessian(f1, x)
}
    # 2. Найдите градиент функции
    #    f2(x1, x2, x3) = (x1 * sin(x2 * cos(x3))) ^ x1 
    #    в точке (3, 2, 1) численным методом
{
  f2 <- function(x)
  {
    return((x[1] * sin(x[2] * cos(x[3]))) ^ x[1])
  }
  x <- c(3, 2, 1)
  grad(f2, x)
  hessian(f2, x)
}
    # 3. Напишите собственный аналог функции grad() и 
    #    сравните ее с оригинальной функцией. Проверьте,
    #    способна ли ваша функция работать с числами повышенной
    #    точности, создаваемыми функцией mpfr из пакета Rmpfr, 
    #    если нет, то обеспечьте данную возможность.
{
  myGrad <- function(func, x, eps = NULL)
  {
    if(is.null(eps))
    {
      eps <- sqrt(.Machine$double.eps) * x
    }
    n <- length(x)
    grad <- rep(0, n)
    for(i in 1:n)
    {
      x_new <- x
      x_new[i] <- x[i] + eps[i]
      grad[i] <- (func(x_new) - func(x)) / eps[i]
    }
    return(grad)
  }
  myGrad(func = f, x = x)          # обычные числа типа double
  myGrad(func = f,                 # числа повышенной точности
         x = c(mpfr("2", 500), 
               mpfr("3", 500)),
         eps = c(mpfr("0.0000000000000000000000000000001", 500), 
                 mpfr("0.0000000000000000000000000000001", 500)))
  grad(func = f, x = x)
}